import pandas as pd
import sys
import numpy as np
import logging
import os

# --- Configura√ß√£o de Logging ---
LOG_FILE_NAME = 'controle_semanal.log'
logging.basicConfig(filename=LOG_FILE_NAME, level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s',
                    encoding='utf-8')
logger = logging.getLogger(__name__)

# --- Configura√ß√µes dos Arquivos e Abas (Vari√°veis RENOMEADAS) ---
PLANILHA_ANTERIOR_PATH = "anterior.xlsx"
ABA_ANTERIOR = "Sheet1"

PLANILHA_SEMANAL_PATH = "semana 18 a 25.xlsx"
ABA_SEMANAL = "Export"

PLANILHA_FUTURA_PATH = "adicional2207.xlsx"
ABA_FUTURA = "Planilha1"

# --- Nomes das Colunas (DEFINIDOS COM EXATID√ÉO PARA CADA PLANILHA) ---
COL_ANTERIOR_CNPJ = "CNPJ/CPF do EC \n(sem / ou -)"
COL_ANTERIOR_NOME = "Raz√£o Social do EC"
COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO = "Valor j√° liquidado ao EC at√© a data base"
COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO = "Valor a liquidar ao EC a partir da data base \n(agenda futura)"

COL_SEMANAL_CNPJ = "CPF/CNPJ"
COL_SEMANAL_NOME = "Raz√£o Social"
COL_SEMANAL_PAGAMENTOS = "Pagamentos ECs Relatorio"

COL_FUTURA_CNPJ = "Cnpj"
COL_FUTURA_NOME = "Nome"
COL_FUTURA_AGENDA_FUTURA = "Valor a Antecipar"

# --- Mensagens de In√≠cio e Log ---
print("=" * 80)
print("             INICIANDO PROCESSAMENTO DE RELAT√ìRIO SEMANAL (controle_semanal.py)             ")
print("=" * 80)
logger.info("Iniciando script de atualiza√ß√£o de relat√≥rio semanal.")


# --- Fun√ß√µes Auxiliares Comuns ---
def padronizar_cnpj(cnpj_series):
    """
    Remove caracteres n√£o num√©ricos de uma s√©rie de CNPJs,
    garantindo que o tipo seja string antes da opera√ß√£o, e removendo '.0' se for float.
    """
    if cnpj_series.empty:
        return pd.Series(dtype=str)

    # Primeiro, converte para string para lidar com floats que viraram '123.0'
    cnpj_str_series = cnpj_series.astype(str)

    # Remove '.0' de n√∫meros que foram lidos como float
    cnpj_str_series = cnpj_str_series.apply(lambda x: x.replace('.0', '') if x.endswith('.0') else x)

    # Remove caracteres n√£o num√©ricos e espa√ßos extras
    return cnpj_str_series.str.replace(r'[^\d]', '', regex=True).str.strip()


def padronizar_nome(nome_series):
    """
    Converte uma s√©rie de nomes para min√∫sculas e remove espa√ßos extras,
    garantindo que o tipo seja string antes da opera√ß√£o.
    """
    if nome_series.empty:
        return pd.Series(dtype=str)
    return nome_series.astype(str).str.lower().str.strip()


def validar_colunas(df, df_path_str, df_name_str, required_cols):
    """
    Verifica se todas as colunas essenciais est√£o presentes no DataFrame.
    Em caso de falha, imprime um erro cr√≠tico e encerra o script.
    """
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        error_msg = (
            f"\n‚ùå ERRO CR√çTICO: As seguintes colunas esperadas N√ÉO foram encontradas no DataFrame de '{df_name_str}'.\n"
            f"   Arquivo: '{df_path_str}'\n"
            f"   Colunas faltando: {missing_cols}\n"
            f"   Por favor, verifique a ortografia exata e a exist√™ncia das colunas no seu arquivo Excel.\n"
            f"   Colunas dispon√≠veis em '{df_name_str}': {list(df.columns)}"
        )
        print(error_msg)
        logger.critical(error_msg)
        sys.exit(1)
    logger.info(f"Todas as colunas essenciais verificadas em {df_name_str}.")


def carregar_planilha_robusto(file_path, sheet_name, display_name):
    """
    Carrega uma planilha Excel de forma robusta, com tratamento de erros para
    arquivo n√£o encontrado, aba inexistente, arquivo vazio ou outros erros.
    """
    if not os.path.exists(file_path):
        error_msg = f"\n‚ùå ERRO FATAL: Arquivo '{file_path}' N√ÉO encontrado.\n   Verifique o caminho e o nome do arquivo."
        print(error_msg)
        logger.critical(error_msg)
        sys.exit(1)

    try:
        print(f"\nüîÑ Carregando {display_name}: '{file_path}' (aba '{sheet_name}')...")
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        print(f"   ‚úÖ {display_name} carregada. Total de linhas: {len(df)}")
        logger.info(f"{display_name} carregada: {file_path} ({sheet_name}) com {len(df)} linhas.")
        return df
    except ValueError as e:
        error_msg = (
            f"\n‚ùå ERRO FATAL: A aba '{sheet_name}' N√ÉO foi encontrada no arquivo '{file_path}'.\n"
            f"   Por favor, verifique o nome exato da aba (case-sensitive).\n"
            f"   Detalhes t√©cnicos: {e}"
        )
        print(error_msg)
        logger.critical(error_msg)
        sys.exit(1)
    except pd.errors.EmptyDataError:
        error_msg = (
            f"\n‚ùå ERRO FATAL: O arquivo '{file_path}' est√° vazio ou n√£o possui dados v√°lidos.\n"
            f"   Verifique o conte√∫do do arquivo."
        )
        print(error_msg)
        logger.critical(error_msg)
        sys.exit(1)
    except Exception as e:
        error_msg = (
            f"\n‚ùå ERRO FATAL: Ocorreu um erro inesperado ao carregar '{file_path}'.\n"
            f"   Verifique se o arquivo n√£o est√° aberto em outro programa e se est√° no formato correto (.xlsx).\n"
            f"   Detalhes t√©cnicos: {e}"
        )
        print(error_msg)
        logger.critical(error_msg)
        sys.exit(1)


# --- IN√çCIO DO FLUXO PRINCIPAL ---

# --- Etapa 1/7: Carregamento de Planilhas ---
print("\n--- Etapa 1/7: Carregamento de Planilhas ---")
df_anterior = carregar_planilha_robusto(PLANILHA_ANTERIOR_PATH, ABA_ANTERIOR, "planilha anterior")
df_semanal = carregar_planilha_robusto(PLANILHA_SEMANAL_PATH, ABA_SEMANAL, "planilha semanal")
df_futura = carregar_planilha_robusto(PLANILHA_FUTURA_PATH, ABA_FUTURA, "planilha futura (agenda futura)")

# --- Etapa 2/7: Valida√ß√£o de Colunas Essenciais ---
print("\n--- Etapa 2/7: Valida√ß√£o de Colunas Essenciais ---")
required_cols_anterior = [COL_ANTERIOR_CNPJ, COL_ANTERIOR_NOME, COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO,
                          COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO]
required_cols_semanal = [COL_SEMANAL_CNPJ, COL_SEMANAL_NOME, COL_SEMANAL_PAGAMENTOS]
required_cols_futura = [COL_FUTURA_CNPJ, COL_FUTURA_NOME, COL_FUTURA_AGENDA_FUTURA]

validar_colunas(df_anterior, PLANILHA_ANTERIOR_PATH, "planilha anterior", required_cols_anterior)
validar_colunas(df_semanal, PLANILHA_SEMANAL_PATH, "planilha semanal", required_cols_semanal)
validar_colunas(df_futura, PLANILHA_FUTURA_PATH, "planilha futura (agenda futura)", required_cols_futura)
print("‚úÖ Todas as colunas essenciais foram encontradas em todas as planilhas.")

# --- Etapa 3/7: Padroniza√ß√£o de Dados e Prepara√ß√£o de Valores Num√©ricos ---
print("\n--- Etapa 3/7: Padronizando CNPJs e Nomes, e preparando valores num√©ricos ---")
try:
    # Planilha Anterior
    df_anterior[COL_ANTERIOR_CNPJ] = df_anterior[COL_ANTERIOR_CNPJ].astype(
        str)  # Garante que a coluna original √© string
    df_anterior['CNPJ_LIMPO'] = padronizar_cnpj(df_anterior[COL_ANTERIOR_CNPJ])
    df_anterior['NOME_LIMPO'] = padronizar_nome(df_anterior[COL_ANTERIOR_NOME])

    for col_val in [COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO, COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO]:
        initial_nan_count = df_anterior[col_val].isnull().sum()
        df_anterior[col_val] = pd.to_numeric(df_anterior[col_val], errors='coerce').fillna(0)
        if initial_nan_count > 0:
            print(
                f"   ‚ö†Ô∏è ATEN√á√ÉO: Coluna '{col_val}' (anterior) continha {initial_nan_count} valores n√£o num√©ricos/vazios, convertidos para 0.")
            logger.warning(
                f"Coluna {col_val} na anterior tinha {initial_nan_count} NaN/n√£o num√©ricos, convertidos para 0.")

    # Planilha Semanal
    df_semanal[COL_SEMANAL_CNPJ] = df_semanal[COL_SEMANAL_CNPJ].astype(
        str)  # Garante que a coluna original √© string
    df_semanal['CNPJ_LIMPO'] = padronizar_cnpj(df_semanal[COL_SEMANAL_CNPJ])
    df_semanal['NOME_LIMPO'] = padronizar_nome(df_semanal[COL_SEMANAL_NOME])
    initial_nan_semanal_pagamentos = df_semanal[COL_SEMANAL_PAGAMENTOS].isnull().sum()
    df_semanal[COL_SEMANAL_PAGAMENTOS] = pd.to_numeric(df_semanal[COL_SEMANAL_PAGAMENTOS], errors='coerce').fillna(0)
    if initial_nan_semanal_pagamentos > 0:
        print(
            f"   ‚ö†Ô∏è ATEN√á√ÉO: Coluna '{COL_SEMANAL_PAGAMENTOS}' (semanal) continha {initial_nan_semanal_pagamentos} valores n√£o num√©ricos/vazios, convertidos para 0.")
        logger.warning(
            f"Coluna {COL_SEMANAL_PAGAMENTOS} na semanal tinha {initial_nan_semanal_pagamentos} NaN/n√£o num√©ricos, convertidos para 0.")

    # Planilha Futura
    df_futura[COL_FUTURA_CNPJ] = df_futura[COL_FUTURA_CNPJ].astype(str)  # Garante que a coluna original √© string
    df_futura['CNPJ_LIMPO'] = padronizar_cnpj(df_futura[COL_FUTURA_CNPJ])
    df_futura['NOME_LIMPO'] = padronizar_nome(df_futura[COL_FUTURA_NOME])
    initial_nan_futura_agenda = df_futura[COL_FUTURA_AGENDA_FUTURA].isnull().sum()
    df_futura[COL_FUTURA_AGENDA_FUTURA] = pd.to_numeric(df_futura[COL_FUTURA_AGENDA_FUTURA],
                                                          errors='coerce').fillna(0)
    if initial_nan_futura_agenda > 0:
        print(
            f"   ‚ö†Ô∏è ATEN√á√ÉO: Coluna '{COL_FUTURA_AGENDA_FUTURA}' (futura) continha {initial_nan_futura_agenda} valores n√£o num√©ricos/vazios, convertidos para 0.")
        logger.warning(
            f"Coluna {COL_FUTURA_AGENDA_FUTURA} na futura tinha {initial_nan_futura_agenda} NaN/n√£o num√©ricos, convertidos para 0.")

    empty_cnpj_anterior = df_anterior[df_anterior['CNPJ_LIMPO'] == ''].shape[0]
    empty_cnpj_semanal = df_semanal[df_semanal['CNPJ_LIMPO'] == ''].shape[0]
    empty_cnpj_futura = df_futura[df_futura['CNPJ_LIMPO'] == ''].shape[0]

    if empty_cnpj_anterior > 0:
        print(
            f"   ‚ö†Ô∏è ATEN√á√ÉO: {empty_cnpj_anterior} linhas na planilha anterior possuem CNPJ vazio ap√≥s padroniza√ß√£o. Isso pode afetar o matching.")
        logger.warning(f"{empty_cnpj_anterior} CNPJs vazios na planilha anterior.")
    if empty_cnpj_semanal > 0:
        print(
            f"   ‚ö†Ô∏è ATEN√á√ÉO: {empty_cnpj_semanal} linhas na planilha semanal possuem CNPJ vazio ap√≥s padroniza√ß√£o. Isso pode afetar o matching.")
        logger.warning(f"{empty_cnpj_semanal} CNPJs vazios na planilha semanal.")
    if empty_cnpj_futura > 0:
        print(
            f"   ‚ö†Ô∏è ATEN√á√ÉO: {empty_cnpj_futura} linhas na planilha futura possuem CNPJ vazio ap√≥s padroniza√ß√£o. Isso pode afetar o matching.")
        logger.warning(f"{empty_cnpj_futura} CNPJs vazios na planilha futura.")

    print("‚úÖ CNPJs e Nomes padronizados e valores num√©ricos preparados em todas as planilhas.")
    logger.info("Padroniza√ß√£o de dados e prepara√ß√£o num√©rica conclu√≠das.")

except Exception as e:
    error_msg = f"\n‚ùå ERRO FATAL: Falha durante a padroniza√ß√£o de dados ou convers√£o de tipo.\n   Detalhes t√©cnicos: {e}"
    print(error_msg)
    logger.critical(error_msg)
    sys.exit(1)

# --- Etapa 4/7: Agrupando dados das planilhas de origem ---
print("\n--- Etapa 4/7: Agrupando dados das planilhas de origem (Semanal e Futura) ---")
try:
    df_semanal_agrupado = df_semanal.groupby(['CNPJ_LIMPO', 'NOME_LIMPO'])[COL_SEMANAL_PAGAMENTOS].sum().reset_index()
    df_semanal_agrupado.rename(columns={COL_SEMANAL_PAGAMENTOS: 'Soma_Pagamentos_Semanal'}, inplace=True)
    print(f"   ‚úÖ Dados da Semanal agrupados por CNPJ e Nome. Total de entradas √∫nicas na semanal: {len(df_semanal_agrupado)}")
    logger.info(f"Dados Semanais agrupados. {len(df_semanal_agrupado)} entradas √∫nicas.")

    # Para a planilha futura, se houver m√∫ltiplos valores para o mesmo CNPJ/Nome,
    # estamos pegando o PRIMEIRO.
    df_futura_agrupado = df_futura.groupby(['CNPJ_LIMPO', 'NOME_LIMPO'])[
        COL_FUTURA_AGENDA_FUTURA].first().reset_index()
    df_futura_agrupado.rename(columns={COL_FUTURA_AGENDA_FUTURA: 'Valor_Agenda_Futura_Futura'}, inplace=True)
    print(
        f"   ‚úÖ Dados da planilha futura agrupados por CNPJ e Nome. Total de entradas √∫nicas: {len(df_futura_agrupado)}")
    logger.info(f"Dados da futura agrupados. {len(df_futura_agrupado)} entradas √∫nicas.")

except Exception as e:
    error_msg = f"\n‚ùå ERRO CR√çTICO: Falha ao agrupar dados das planilhas de origem.\n   Detalhes t√©cnicos: {e}"
    print(error_msg)
    logger.critical(error_msg)
    sys.exit(1)

# --- Etapa 5/7: Identificando e adicionando novas lojas da Semanal ao relat√≥rio ---
print("\n--- Etapa 5/7: Identificando e adicionando novas lojas da Semanal ao relat√≥rio ---")

novas_lojas_encontradas = []
df_novas_lojas_para_adicionar_list = [] # Usar uma lista de dicion√°rios para construir o DF

# Cria um set de chaves (CNPJ_LIMPO, NOME_LIMPO) do df_anterior ORIGINAL
# para identificar o que j√° existe no relat√≥rio.
chaves_anterior_existente = set(zip(df_anterior['CNPJ_LIMPO'], df_anterior['NOME_LIMPO']))

for _, row_semanal in df_semanal_agrupado.iterrows():
    semanal_cnpj_limpo = row_semanal['CNPJ_LIMPO']
    semanal_nome_limpo = row_semanal['NOME_LIMPO']
    semanal_pagamento = row_semanal['Soma_Pagamentos_Semanal']

    # VERIFICA SE A LOJA J√Å EXISTE NO RELAT√ìRIO ANTERIOR
    if (semanal_cnpj_limpo, semanal_nome_limpo) not in chaves_anterior_existente:
        nova_linha_dict = {}

        # Tenta pegar os valores originais da semanal antes da padroniza√ß√£o para a nova linha
        original_semanal_row = df_semanal[(df_semanal['CNPJ_LIMPO'] == semanal_cnpj_limpo) & (df_semanal['NOME_LIMPO'] == semanal_nome_limpo)]

        if not original_semanal_row.empty:
            # Pega o primeiro valor original encontrado para CNPJ e Nome
            original_cnpj = str(original_semanal_row[COL_SEMANAL_CNPJ].iloc[0])
            if original_cnpj.endswith('.0'):
                original_cnpj = original_cnpj.replace('.0', '')
            nova_linha_dict[COL_ANTERIOR_CNPJ] = original_cnpj

            nova_linha_dict[COL_ANTERIOR_NOME] = original_semanal_row[COL_SEMANAL_NOME].iloc[0]
        else:
            # Fallback para os valores padronizados se o original n√£o for encontrado (improv√°vel)
            nova_linha_dict[COL_ANTERIOR_CNPJ] = semanal_cnpj_limpo
            nova_linha_dict[COL_ANTERIOR_NOME] = semanal_nome_limpo

        nova_linha_dict[COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO] = semanal_pagamento
        nova_linha_dict[COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO] = 0.0 # Nova loja come√ßa com 0 para agenda futura

        # Preenche outras colunas com NaN (ou 0 se for num√©rico, dependendo da necessidade) para as novas lojas
        for col in df_anterior.columns:
            if col not in nova_linha_dict:
                if col in [COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO, COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO]:
                     nova_linha_dict[col] = 0.0
                else:
                    nova_linha_dict[col] = np.nan

        # Adiciona as colunas padronizadas para o futuro re-c√°lculo da chave
        nova_linha_dict['CNPJ_LIMPO'] = semanal_cnpj_limpo
        nova_linha_dict['NOME_LIMPO'] = semanal_nome_limpo

        df_novas_lojas_para_adicionar_list.append(nova_linha_dict)
        novas_lojas_encontradas.append(
            f"CNPJ: {nova_linha_dict[COL_ANTERIOR_CNPJ]}, Loja: {nova_linha_dict[COL_ANTERIOR_NOME]}, Valor Pagamento Semanal: {semanal_pagamento:.2f}")

# Concatena as novas lojas APENAS SE HOUVEREM
if df_novas_lojas_para_adicionar_list:
    df_novas_lojas_para_adicionar_df = pd.DataFrame(df_novas_lojas_para_adicionar_list)
    print("\n   --- Novas lojas encontradas e adicionadas ao relat√≥rio: ---")
    for loja_info in novas_lojas_encontradas:
        print(f"   ‚ûï {loja_info}")
    print("   ---------------------------------------------------------")
    df_anterior_atualizado = pd.concat([df_anterior, df_novas_lojas_para_adicionar_df], ignore_index=True)
    print(f"   ‚úÖ Total de lojas na planilha anterior ap√≥s adicionar novas: {len(df_anterior_atualizado)}")
    logger.info(f"Novas lojas adicionadas: {len(novas_lojas_encontradas)}")
else:
    print("   ‚úÖ Nenhuma nova loja encontrada na planilha semanal para adicionar.")
    df_anterior_atualizado = df_anterior.copy()

# Garante que as colunas _LIMPO est√£o atualizadas para o df_anterior_atualizado
df_anterior_atualizado['CNPJ_LIMPO'] = padronizar_cnpj(df_anterior_atualizado[COL_ANTERIOR_CNPJ])
df_anterior_atualizado['NOME_LIMPO'] = padronizar_nome(df_anterior_atualizado[COL_ANTERIOR_NOME])

logger.info("Processo de identifica√ß√£o de novas lojas conclu√≠do.")

# --- IN√çCIO DA NOVA ETAPA: Remo√ß√£o e Consolida√ß√£o de Duplicatas ---
print("\n--- Etapa 5.5/7: Verificando e Consolidando Duplicatas ---")
duplicatas = df_anterior_atualizado.duplicated(subset=['CNPJ_LIMPO', 'NOME_LIMPO'], keep=False)
num_duplicatas_detectadas = duplicatas.sum()
if num_duplicatas_detectadas > 0:
    print(f"   ‚ö†Ô∏è ATEN√á√ÉO: {num_duplicatas_detectadas} linhas com CNPJ/Nome duplicados detectadas no relat√≥rio.")
    logger.warning(f"{num_duplicatas_detectadas} linhas duplicadas detectadas antes da consolida√ß√£o.")
    agg_funcs = {
        COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO: 'sum',
        COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO: 'first'
    }
    for col in df_anterior_atualizado.columns:
        if col not in [COL_ANTERIOR_CNPJ, COL_ANTERIOR_NOME, 'CNPJ_LIMPO', 'NOME_LIMPO',
                       COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO, COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO]:
            agg_funcs[col] = 'first'
    agg_funcs[COL_ANTERIOR_CNPJ] = 'first'
    agg_funcs[COL_ANTERIOR_NOME] = 'first'
    df_anterior_atualizado = df_anterior_atualizado.groupby(['CNPJ_LIMPO', 'NOME_LIMPO'], as_index=False).agg(agg_funcs)
    num_linhas_apos_consolidacao = len(df_anterior_atualizado)
    print(f"   ‚úÖ Duplicatas consolidadas. Total de linhas ap√≥s consolida√ß√£o: {num_linhas_apos_consolidacao}")
    logger.info(f"Duplicatas consolidadas. {num_linhas_apos_consolidacao} linhas ap√≥s consolida√ß√£o.")
else:
    print("   ‚úÖ Nenhuma duplicata encontrada para consolida√ß√£o.")
    logger.info("Nenhuma duplicata encontrada para consolida√ß√£o.")

# --- FIM DA NOVA ETAPA ---

# --- Etapa 6/7: Realizar Match e Atualiza√ß√µes de Valores (Agora com Fuzzy Match apenas no CNPJ para a Futura) ---
print("\n--- Etapa 6/7: Realizando match e atualizando valores nas colunas do relat√≥rio ---")

semanal_combined_map = {(row['CNPJ_LIMPO'], row['NOME_LIMPO']): row['Soma_Pagamentos_Semanal']
                       for _, row in df_semanal_agrupado.iterrows()}
# N√£o usaremos o mapa da futura, faremos o merge
# adicional_combined_map = {(row['CNPJ_LIMPO'], row['NOME_LIMPO']): row['Valor_Agenda_Futura_Futura']
#                           for _, row in df_futura_agrupado.iterrows()}

lojas_somadas_semanal = 0
lojas_substituidas_futura = 0

# Itera sobre cada linha do DataFrame de entrega atualizado
for idx, row in df_anterior_atualizado.iterrows():
    cnpj_anterior = row['CNPJ_LIMPO']
    nome_anterior = row['NOME_LIMPO']
    chave_combinada = (cnpj_anterior, nome_anterior)

    # === Atualiza√ß√£o da coluna de SOMA (Valor j√° liquidado ao EC at√© a data base) ===
    # Esta parte permanece inalterada, pois a regra de somar do BI (semanal) se mant√©m.
    if chave_combinada in semanal_combined_map:
        pagamento_semanal_para_somar = semanal_combined_map[chave_combinada]
        # Atualiza a linha usando .loc para melhor performance e seguran√ßa
        df_anterior_atualizado.loc[idx, COL_ANTERIOR_VALOR_LIQUIDADO_PASSADO] += pagamento_semanal_para_somar
        lojas_somadas_semanal += 1

# === Implementando o Fuzzy Match para a planilha futura APENAS PELO CNPJ ===
print("\n   üîÑ Realizando o 'fuzzy match' (merge) da planilha futura apenas pelo CNPJ...")

# Prepara a planilha futura para o merge, renomeando as colunas necess√°rias
df_futura_para_merge = df_futura_agrupado.rename(columns={'CNPJ_LIMPO': 'CNPJ_LIMPO_FUTURA',
                                                          'Valor_Agenda_Futura_Futura': 'Valor_Agenda_Futura_Futura'})
# Mant√©m apenas o CNPJ limpo e a coluna de valor
df_futura_para_merge = df_futura_para_merge[['CNPJ_LIMPO_FUTURA', 'Valor_Agenda_Futura_Futura']]

# Realiza o merge. O 'how="left"' garante que todas as linhas da planilha anterior sejam mantidas.
# O 'on' √© a chave de jun√ß√£o, que √© apenas o CNPJ_LIMPO.
df_merged = pd.merge(df_anterior_atualizado,
                     df_futura_para_merge,
                     left_on='CNPJ_LIMPO',
                     right_on='CNPJ_LIMPO_FUTURA',
                     how='left')

# Agora, substitui os valores na coluna de agenda futura da planilha anterior,
# usando os valores que vieram do merge.
# Se o valor do merge for NaN (n√£o encontrou correspond√™ncia), o valor original √© mantido.
df_merged[COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO] = df_merged['Valor_Agenda_Futura_Futura'].fillna(
    df_merged[COL_ANTERIOR_VALOR_LIQUIDAR_FUTURO])

# Contagem de quantas linhas foram substitu√≠das
# Pega o n√∫mero de linhas onde a coluna do merge n√£o √© nula
lojas_substituidas_futura = df_merged['Valor_Agenda_Futura_Futura'].notna().sum()

# Remove as colunas tempor√°rias criadas pelo merge
df_anterior_atualizado = df_merged.drop(columns=['CNPJ_LIMPO_FUTURA', 'Valor_Agenda_Futura_Futura'])


print(f"\n   ‚úÖ Atualiza√ß√£o de valores conclu√≠da.")
print(f"      - Lojas com valores 'j√° liquidado' SOMADOS (da semanal): {lojas_somadas_semanal}")
print(
    f"      - Lojas com valores 'a liquidar (agenda futura)' SUBSTITU√çDOS (da futura): {lojas_substituidas_futura}")

if lojas_substituidas_futura == 0 and len(df_futura_agrupado) > 0:
    print("\n   ‚ö†Ô∏è ATEN√á√ÉO: Nenhuma atualiza√ß√£o de 'agenda futura' foi realizada pela planilha futura.")
    logger.warning("Nenhuma atualiza√ß√£o de agenda futura da planilha futura foi realizada.")

logger.info(
    f"Atualiza√ß√£o de valores conclu√≠da. Somadas: {lojas_somadas_semanal}, Substitu√≠das: {lojas_substituidas_futura}")

# --- Etapa 7/7: Finaliza√ß√£o e Salvamento da Planilha Atualizada ---
print("\n--- Etapa 7/7: Finaliza√ß√£o e Salvamento da Planilha Atualizada ---")

# Remove as colunas tempor√°rias de CNPJ/Nome padronizados
df_final = df_anterior_atualizado.drop(columns=['CNPJ_LIMPO', 'NOME_LIMPO'])

# Garante que as colunas na planilha final mantenham a ordem original da planilha anterior.
colunas_originais_df_anterior_inicial = df_anterior.columns.tolist()
colunas_finais_ordenadas = [col for col in colunas_originais_df_anterior_inicial if col in df_final.columns]
for col in df_final.columns:
    if col not in colunas_finais_ordenadas:
        colunas_finais_ordenadas.append(col)

df_final = df_final[colunas_finais_ordenadas]

# Salva o DataFrame final no mesmo arquivo da planilha anterior, substituindo a aba.
try:
    print(f"\nüíæ Salvando planilha atualizada em: '{PLANILHA_ANTERIOR_PATH}' (aba '{ABA_ANTERIOR}')...")
    with pd.ExcelWriter(PLANILHA_ANTERIOR_PATH, engine='openpyxl', mode='a',
                        if_sheet_exists='replace') as writer:
        df_final.to_excel(writer, sheet_name=ABA_ANTERIOR, index=False)

    print(f"\nüéâ SUCESSO! A planilha '{PLANILHA_ANTERIOR_PATH}' foi atualizada com sucesso.")
    print("   Verifique o arquivo e o log para os resultados finais.")
    logger.info("Script finalizado com sucesso. Planilha salva.")

except Exception as e:
    error_msg = (
        f"\n‚ùå ERRO FATAL: Ocorreu um erro ao salvar a planilha atualizada.\n"
        f"   Por favor, feche o arquivo '{PLANILHA_ANTERIOR_PATH}' se estiver aberto\n"
        f"   e tente novamente. Certifique-se de ter permiss√£o de escrita na pasta.\n"
        f"   Detalhes t√©cnicos: {e}"
    )
    print(error_msg)
    logger.critical(error_msg)
    sys.exit(1)

print("\n" + "=" * 80)
print("               PROCESSAMENTO CONCLU√çDO COM SUCESSO!               ")
print("=" + "=" * 80)
logger.info("Fim da execu√ß√£o do script.")
